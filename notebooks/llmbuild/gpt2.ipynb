{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151d154c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in text: 5145\n",
      "\n",
      "=== Batch 1 ===\n",
      "Final embeddings shape: torch.Size([512, 1024, 768])\n",
      "Decoded snippet of first sequence: I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a ...\n",
      "\n",
      "\n",
      "=== Batch 2 ===\n",
      "Final embeddings shape: torch.Size([512, 1024, 768])\n",
      "Decoded snippet of first sequence:  to put beauty into circulation,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carl ...\n",
      "\n",
      "\n",
      "=== Batch 3 ===\n",
      "Final embeddings shape: torch.Size([512, 1024, 768])\n",
      "Decoded snippet of first sequence: , presenting a neutral surface to work on--forming, as it were, so inevitably the background of her own picture--had lent herself in an unusual degree to the display of this false virtuosity. The pict ...\n",
      "\n",
      "\n",
      "=== Batch 4 ===\n",
      "Final embeddings shape: torch.Size([512, 1024, 768])\n",
      "Decoded snippet of first sequence:  little too much amazement escape through my surprise, for he answered with a deprecating laugh: \"Yes--she's an awful simpleton, you know, Mrs. Stroud. Her only idea was to have him done by a fashiona ...\n",
      "\n",
      "\n",
      "=== Batch 5 ===\n",
      "Final embeddings shape: torch.Size([13, 1024, 768])\n",
      "Decoded snippet of first sequence:  of working? My strokes began to go a little wild--I felt nervous and uncertain.\n",
      "\n",
      "\"Once, when I looked up, I seemed to see a smile behind his close grayish beard--as if he had the secret, and were amu ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken   # GPT-2 BPE tokenizer\n",
    "\n",
    "# -----------------------------\n",
    "# 1. PARAMETERS\n",
    "# -----------------------------\n",
    "batch_size = 512   #GPT-2 small Batch Size is 512 sequence\n",
    "max_length = 1024  # GPT-2 small context window size or each sequence length\n",
    "stride = 2         # GPT-2 STRIDE is same as max_length. It means, there is no stride. In our case, we will have it as 100.\n",
    "embedding_dim = 768  # GPT-2 small hidden size\n",
    "\n",
    "# -----------------------------\n",
    "# 2. READ RAW TEXT\n",
    "# -----------------------------\n",
    "with open(\"../../_data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. TOKENIZER (GPT-2 BPE)\n",
    "# -----------------------------\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokens = tokenizer.encode(raw_text)\n",
    "vocab_size = tokenizer.n_vocab\n",
    "print(\"Total tokens in text:\", len(tokens))\n",
    "\n",
    "# -----------------------------\n",
    "# 4. SLIDING WINDOW DATASET\n",
    "# -----------------------------\n",
    "class SlidingWindowDataset(Dataset):\n",
    "    \"\"\"Creates input/target sequences using a sliding window approach.\"\"\"\n",
    "    def __init__(self, tokens, max_length, stride):\n",
    "        self.tokens = tokens\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "\n",
    "        i = 0\n",
    "        while i + max_length < len(tokens):\n",
    "            seq_in = tokens[i : i + max_length]\n",
    "            seq_out = tokens[i + 1 : i + max_length + 1]\n",
    "            self.inputs.append(seq_in)\n",
    "            self.targets.append(seq_out)\n",
    "            i += stride\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx]), torch.tensor(self.targets[idx])\n",
    "\n",
    "\n",
    "def create_dataloader_v1(raw_text, batch_size, max_length, stride, shuffle=False):\n",
    "    tokens = tokenizer.encode(raw_text)\n",
    "    dataset = SlidingWindowDataset(tokens, max_length, stride)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size, max_length, stride, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. EMBEDDING LAYERS\n",
    "# -----------------------------\n",
    "# Token embedding\n",
    "token_embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "# Positional embedding (your object)\n",
    "position_embedding_layer = torch.nn.Embedding(num_embeddings=max_length, embedding_dim=embedding_dim)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. GENERATE FINAL EMBEDDINGS\n",
    "# -----------------------------\n",
    "all_embeddings = []\n",
    "for batch_index, (input_tensor, target_tensor) in enumerate(dataloader):\n",
    "    # input_tensor shape: (batch_size, seq_len)\n",
    "    batch_size_current, seq_len = input_tensor.shape\n",
    "\n",
    "    print(f\"\\n=== Batch {batch_index+1} ===\")\n",
    "\n",
    "    # Create position indices once per sequence\n",
    "    positions = torch.arange(seq_len, dtype=torch.long)  # (seq_len,)\n",
    "    pos_emb = position_embedding_layer(positions)        # (seq_len, embedding_dim)\n",
    "\n",
    "    # Compute embeddings for the entire batch at once\n",
    "    token_emb = token_embedding_layer(input_tensor)      # (batch_size, seq_len, embedding_dim)\n",
    "    final_emb = token_emb + pos_emb.unsqueeze(0)         # broadcast positional embedding\n",
    "\n",
    "    print(\"Final embeddings shape:\", final_emb.shape)    # (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "    # Optional: decode and show first sequence of the batch\n",
    "    decoded_text = tokenizer.decode(input_tensor[0].tolist())\n",
    "    print(\"Decoded snippet of first sequence:\", decoded_text[:200], \"...\\n\")\n",
    "\n",
    "    all_embeddings.append(final_emb)     # store for later use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff3254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177bc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (.venv)",
   "language": "python",
   "name": "buildllm-venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
